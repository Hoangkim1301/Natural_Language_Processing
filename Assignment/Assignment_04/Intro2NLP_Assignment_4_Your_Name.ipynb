{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Natural Language Processing: Assignment 4\n",
    "\n",
    "In this exercise we'll practice training and testing classifiers as well as feature extraction using spaCy.\n",
    "\n",
    "- You can use built-in Python packages, spaCy scikit-learn and Pandas.\n",
    "- Please comment your code\n",
    "- Submissions are due Wednesday at 23:59 **only** on Ilias: **Assignmnets >> Student Submissions >> Assignment 4 (Deadline: 01.06.2022, at 23:59)**\n",
    "\n",
    "- Name the file aproppriately: \"Assignment_4_\\<Your_Name\\>.ipynb\" and submit only the Jupyter Notebook file.\n",
    "- Please use relative path, your code should work on my computer if the Jupyter Notebook and the file are both in the same directory.\n",
    "\n",
    "Example: file_name = rural.txt, **DON'T use:** /Users/ComputerName/Username/Documents/.../rural.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 (4 points)\n",
    "\n",
    "The goal of this task is to train and test classifiers provided in scikit-learn, using two datasets `rural.txt` and `science.txt`.\n",
    "\n",
    "a) Each file (rural and science) contains sentence-wise documents. You should create a dataframe containing two columns: \"Document\" and \" Class\", as shown below. This dataframe will be used later as input for the vectorizer.\n",
    "\n",
    "|Document                             |Class |\n",
    "| ------------------------------------|----- | \n",
    "|PM denies knowledge of AWB kickbacks | rural |\n",
    "|The crocodile ancestor fossil, found...| science |\n",
    "\n",
    " \n",
    "b) Split the data into train (70%) and test (30%) sets and use the tf-idf-vectorizer to train following classifiers provided by scikit-learn:\n",
    "\n",
    "- naive_bayes.GaussianNB()\n",
    "- svm.LinearSVC(). \n",
    "\n",
    "c) Evaluate both classifiers using the test set, report accuracy, recall, precision, f1 scores and confusion matrix.\n",
    "\n",
    "**Hints:**\n",
    "1. The Gaussian NB Classifier takes a dense matrix as input and the output of the vectorizer is a sparse matrix. Use my_matrix.toarray() for this conversion.\n",
    "2. You can play around with various parameters in both the tf-idf-vectorizer and the classifier to get a better performance in terms of the accuracy. (In the exercise, we will discuss the accuracy of your model.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here comes your code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 (3 points)\n",
    "\n",
    "Write a function `extract_features(my_string)` that takes a string as input and returns a list with extracted features using spaCy.\n",
    "\n",
    "This is an open task, it's up to you which features you want to use.\n",
    "\n",
    "**Example:** You have the following string:\n",
    "\n",
    "|String (Document)                             |\n",
    "| ------------------------------------|\n",
    "|PM denies knowledge of AWB kickbacks | \n",
    "\n",
    "Your function should create a list for this string, e.g., [1,0,0,3,0,0,1].\n",
    "\n",
    "Each of these positions represents a feature. For instance, the first position denotes `has a proper noun?`, the second one, `has punctuation?`, the third one, `number of adjectives?`, etc. You should create your own features and it is entirely up to you how many features you create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(my_string):\n",
    "    extracted_features = []\n",
    "    # here comes your code\n",
    "    return(extracted_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 (3 points)\n",
    "\n",
    "a) Using the function from task 2, create features for each document in the dataframe you built in task 1 and train both classifiers.\n",
    "\n",
    "b) Report the evaluation metrics for the same test set you have in task 1: Accuracy, Precision and Recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here comes your code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
