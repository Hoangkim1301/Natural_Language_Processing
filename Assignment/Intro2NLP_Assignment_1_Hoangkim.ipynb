{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Natural Language Processing: Assignment 1\n",
    "\n",
    "In this exercise we'll practice tokenization, lemmatization and stemming\n",
    "\n",
    "- Please comment your code\n",
    "- Submissions are due Wednesday at 23:59 **only** on Ilias: **Assignmnets >> Student Submissions >> Assignment 1 (Deadline: 03.05.2023, at 23:59)**\n",
    "\n",
    "- Name the file aproppriately \"Assignment_1_\\<Your_Name\\>.ipynb\".\n",
    "- Please use relative paths, your code should run on my computer if the notebook and the file are both in the same directory.\n",
    "\n",
    "Example: file_name = lemmatization-en.txt >> **DON'T use:** /Users/ComputerName/Username/Documents/.../lemmatization-en.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1 (3 points)\n",
    "\n",
    "Write a function `extract_words_tokens(any_string)` that takes a string as input and returns two numbers:\n",
    "1. num_words: The number of words in string\n",
    "2. num_tokens: The number of tokens in string (Please use the character-based tokenization.)\n",
    "\n",
    "**Hint:** The string can contain special charecters, such as: \"!\", \",\", \":\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words_tokens(any_string):\n",
    "    #split a string and store in a list\n",
    "    resList = any_string.split(\" \")\n",
    "    num_words = len(resList)\n",
    "    \n",
    "    print(num_words)\n",
    "    \n",
    "    #split a word into tonken, store to a list after each loop and add length to num_tonkens\n",
    "    num_tokens = 0\n",
    "    tonken = list()\n",
    "    for x in resList:\n",
    "        characters = [char for char in x]\n",
    "        tonken = tonken + characters\n",
    "        num_tokens += len(characters)\n",
    "    \n",
    "    #test print the characters tonken\n",
    "    print(tonken)\n",
    "    return(print(any_string, \":\", \"num_words:\", num_words, \"and\", \"num_tokens:\", num_tokens, \"respectively\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2 (4 points)\n",
    "\n",
    "Write a function `lemmatize(any_string, file_name)` that takes as input any string and a file-name: `lemmatization-en.txt` (please download the file [here](https://github.com/michmech/lemmatization-lists/blob/master/lemmatization-en.txt), it's a tab separated) and returns a dictionary with all words as keys and the lemma of the words as values.\n",
    "\n",
    "**Hint:** To tokenize the string, please use the whitespace as the seperator. The string doesn't contain any special characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(any_string, file_name):\n",
    "    #here comes your code\n",
    "    return(print(dictionary_of_lemmatized_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.3 (3 points)\n",
    "\n",
    "Write a function `stemmer(any_string)` that takes a string as input an returns a string processed with their stem.\n",
    "\n",
    "Create rules only for the following cases:\n",
    "\n",
    "- study - studi\n",
    "- studies - studi\n",
    "- studying - studi\n",
    "- studied - studi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmer(any_string):\n",
    "    #here comes your code\n",
    "    return(print(stemmed_string))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
